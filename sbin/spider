#!/usr/bin/env php
<?php

date_default_timezone_set('PRC');
$path = dirname(__DIR__);

/**
 * 输出消息
 *
 */
$echo = function() {
    foreach(func_get_args() as $msg) {
        echo <<<EOT

$msg

EOT;
    }
    echo <<<EOT


EOT;
};
/**
 * docker-compose 执行命令
 * @param string $command
 *
 */
$docker = function($command, $echo = true) use($path) {
    $str = "docker-compose -f $path/etc/docker-compose.yml -p spider $command";
    if ($echo) {
        system($str);
    } else {
        exec($str, $res);
        return $res;
    }
};
/**
 * 读文件
 * @param string $filename
 *
 *
 */
$getFile = function($filename) use($path) {
    substr($filename, 0, 1) == '/' or $filename = $path.'/'.$filename;
    return file_exists($filename) ? 
        file_get_contents($filename) : false;
};

/**
 * 写文件
 * @param string $filename
 *
 */
$setFile = function($filename, $data, $append = false) use($path) {
    substr($filename, 0, 1) == '/' or $filename = $path.'/'.$filename;
    return $append ? file_put_contents($filename, $data, FILE_APPEND) : 
        file_put_contents($filename, $data);
};

/**
 * 安装spider
 *
 *
 */
$spiderInstall = function($command) use($path) {
    //step1 pull docker images
    system("docker run --rm -it wurstmeister/zookeeper echo 'Pulling zookeeper success...'");
    system("docker run --rm -it wurstmeister/kafka echo 'Pulling kafka success...'");
    system("docker run --rm -it redis echo 'Pulling redis success...'");
    system("docker run --rm -it composer echo 'Pulling composer success...'");
    system("docker run --rm -it richarvey/nginx-php-fpm echo 'Pulling nginx success...'");

    //step2, install composer packages
    $crawler = "$path/src/crawler";
    $kafka = "$path/src/kafka";

    system("docker run --rm -v $kafka:/app -it composer $command");
    system("docker run --rm -v $crawler:/app -it composer $command");

    //step2, check packages
    exec("docker run --rm -v $kafka:/app -it composer show -i", $res1);
    exec("docker run --rm -v $crawler:/app -it composer show -i", $res2);
    if (count($res1) < 3 || count($res2) < 7) {
        return false;
    }
    system("docker run --rm -v $crawler:/app -it composer dump-autoload -o");
    return true;
};
/**
 * 爬取url
 * consumer容器
 *
 * @param array $urls
 *
 *
 */
$spiderRun = function($url) use($echo, $docker) {
    $topic = parse_url($url)['host'];
    if (empty($topic)) {
        exit($echo("Invalid url: $url"));
    }
    
    $res = $docker("top consumer | grep $topic", false);
    echo "Sending to producer...";
    if (empty($res)) {
        $docker("exec -d consumer php consumer.php $topic", false);
    }
    $docker("exec crawler curl -d 'url=$url' crawler/crawler/start");
};

/**
 * 清空爬虫缓存
 *
 * @param string $domain
 * @param string action <clear | truncate>
 * clear: 删除url缓存，图片不会重爬
 * truncate: 删除所有缓存，图片会重爬
 *
 */
$spiderCache = function($domain, $action) {
    $docker("exec crawler curl -d 'domain=$domain' crawler/crawler/$action");
};

/**
 * 查看爬虫是否启动
 * 
 * @return bool
 *
 */
$checkSpider = function() {
    exec("docker ps | grep spider_", $res);
    return count($res) == 5 ? true : false;
};


//set args
$command = isset($argv[1]) ? $argv[1] : '';
$option = isset($argv[2]) ? $argv[2] : '';

//check if installed
if (!in_array($command, ['install', 'update']) && 
    !$getFile('src/.installed')) {
        exit($echo('Spider has not installed',
            'Use [spider install] first'
        ));
}

switch ($command) {
    case 'install':
    case 'update':
        //check if installed
        $installed = 'src/.installed';
        if ($command == 'install' && $getFile($installed)) {
            $echo("Spider has been installed...",
            "If you need to reinstall use [spider update]"
            );
        } else if ($spiderInstall($command)) {
            $setFile($installed, date('Y-m-d H:i:s', time()), true);
            $echo('Spider installed success...');
        }
    break;
    case 'start':
        $docker('up -d');
        break;

    case 'restart':
        $docker("restart $option");
        break;

    case 'recreate':
        fwrite(STDOUT, "重新创建所有容器，数据将会删除，确定(y/n): ");
        if (strtolower(trim(fgets(STDIN))) == 'y') {
            $docker("up -d --force-recreate");
        }
        break;

    case 'run':
        $his_file = 'src/kafka/.history';

        switch ($option) {
            case '':
            case '-h':
            case '--help':
                $help = <<<EOT
Usage:
  spider run [Options | Urls]

Options:
  [-h | --help]            show spider run help
  [--history]              show spider run histories

Urls:
  spider run url           Crawl url
  spider run url1 url2     Crawl url1 and url2


EOT;
                exit($help);
            case '--history':
                //delete hisotry
                if (isset($argv[3]) && 
                    $argv[3] == 'clear') {
                    $setFile($his_file, '');
                    exit($echo('All spider run histories are cleared'));
                }
                echo $getFile($his_file);
                break;
            default:
                //check status
                if (!$checkSpider()) {
                    exit($echo('Spider is now not running',
                    'Use [spider start] first'));
                }
                $urls = array_slice($argv, 2);

                $date = date('Y-m-d H:i:s', time());
                foreach($urls as $url) {
                    if (substr($option, 0, 4) != 'http')
                        exit($echo('Url must start with http|https'));

                    //记录历史
                    $setFile($his_file, "[$date] ".$url."\n", true);
                    $spiderRun($url);
                }
        }
        break;
    case 'list':
        $topics = $docker('top consumer | grep consumer.php', false);
        if (!empty($topics)) {
            $echo('Spider is running topics: ');
            foreach($topics as $topic) {
                $arr = explode(' ', $topic);
                $topic = end($arr);
                echo "    - $topic\n";
            }
            echo "\n";
        } else {
            $echo('There is no topic running...');
        }
        break;
    case 'kill':
        switch($option) {
            case '':
            case '-h':
            case '--help':
                $help = <<<EOT
Usage:
  spider kill [Topics]

Use [spider list] to show available topics


EOT;
                exit($help);
            default:
                $topics = $docker('top consumer | grep consumer.php', false);
                if (!empty($topics)) {
                    foreach($topics as $topic) {
                        $arr = explode(' ', $topic);
                        $topic = end($arr);
                        foreach(array_slice($argv, 2) as $t) {
                            if ($t == $topic) {
                                $docker("exec consumer pkill -f $topic");
                            }
                        }

                    }
                    exit;
                }
                $echo("This is no such topic running: $option");
                break;
        }
        break;
    case 'stop':
        $docker('stop');
        break;
    case 'rm':
        $docker('rm -f');
        break;
    case 'remove':
        if ($option == '-y') {
            $docker('down');
        } else {
            fwrite(STDOUT, "确定删除爬虫(y/n): ");
            if (strtolower(trim(fgets(STDIN))) == 'y')
                $docker('down');
        }
        break;
    case 'status':
        $docker('ps');
        break;
    case 'log':
        switch($option) {
            case '-l':
            case '--ls':
                $logs = scandir("$path/logs");
                echo "Available logs:\n";
                foreach($logs as $l) {
                    if (empty($l) || substr($l, 0, 1) == '.') 
                        continue;
                    echo "  ".current(explode('-', $l))."\n";
                }
                echo "  docker";
                break;
            case '':
            case '-h':
            case '--help':
                $help = <<<EOT
Usage:
  spider log [Options]

Options:
  [-h | --help] show usage of log command
  [-l | --ls]   list available logs

  spider        default, tail spider log by date
  producer      tail producer log by date
  docker        tail docker compose logs
  access        tail nginx access log
  debug         tail debug log


EOT;
                exit($help);
                break;
            case 'docker':
                $docker('logs -f');
                break;
            case 'access':
            case 'producer':
            case 'spider':
            case 'debug':
                $d = date('Y-m-d', time());
                !empty($option) or $option = 'spider';
                system("tail -f $path/logs/$option-$d.log");
                break;
            case 'crawler':
            case 'consumer':
            case 'kafka':
                $docker("logs -f $option");
                break;
            default:
                exit($echo("$option log not found"));
        }

        break;
    case 'clear':
    case 'truncate':
        if (!$checkSpider())
            $eixt('Spider is not running...');

        if (empty($option)) {
            $help = <<<EOT
Usage:
  spider clear [Urls]

Example:
  spider clear all  clear all spiders cache
  spider clear url  clear spider url cache


EOT;
            exit($help);
        }

        $url = substr($option, 0 ,4) == 'http' ? 
            $option : 'http://'.$option;

        $domain = parse_url($url['host']);
        if (empty($domain))
            exit($echo('Invalid url: '.$option));

        $spiderCache($domain, $command);
        break;
    case 'top':
    case 'attach':
        if (empty($option)) {
            $help = <<<EOT
Usage:
  spider $command [Service]

Service:
  consumer  
  crawler
  kafka


EOT;
            exit($help);
        }
        if ($command == 'attach') {
            $docker("exec $option /bin/bash");
        } else {
            $docker("$command $option");
        }
        break;
    default:
        $usage = <<<EOT

Usage:
  spider [Commands] [Options]

Commands:
  install    install spider
  update     update packages and reinstall spider
  start      start spider
  run        crawl urls
  list       show running topics
  restart    restart spider
  stop       stop spider
  remove     stop and delete spider
  log        show spider logs
  status     show spider status
  top        display the running processes
  kill       kill running spider
  clear      clear url cache 
  truncate   clear url and image cache


EOT;
        exit($usage);
}
